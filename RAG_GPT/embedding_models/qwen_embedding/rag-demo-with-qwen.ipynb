{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from attr.validators import instance_of\n",
    "#创建集合单元\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, MilvusClient\n",
    "\n",
    "client = MilvusClient(uri=\"http://192.168.200.130:19530\")\n",
    "\n",
    "def create_collection():\n",
    "    # 定义字段 schemas\n",
    "    id_field = FieldSchema(name=\"id\", dtype=DataType.INT64, auto_id=True, is_primary=True)\n",
    "    url_field = FieldSchema(name=\"url\", dtype=DataType.VARCHAR, max_length=65535)\n",
    "    content_field = FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=65535)\n",
    "    vector_field = FieldSchema(name=\"content_vector\", dtype=DataType.FLOAT_VECTOR, dim=3584)\n",
    "    publish_time_field = FieldSchema(name=\"publish_time\", dtype=DataType.INT64)\n",
    "\n",
    "    # 创建 Collection schema\n",
    "    schema = CollectionSchema(\n",
    "        fields=[id_field, url_field, content_field, vector_field, publish_time_field],\n",
    "        description=\"CUMT_GPT的Qwen数据集\"\n",
    "    )\n",
    "\n",
    "    # 创建 Collection\n",
    "    collection_name = \"cumt_gpt_qwen\"\n",
    "    if client.has_collection(collection_name):\n",
    "        client.drop_collection(collection_name)\n",
    "\n",
    "    client.create_collection(collection_name=collection_name, schema=schema)\n",
    "\n",
    "    # 为 content_vector 创建索引\n",
    "    # index_params = client.prepare_index_params()\n",
    "    # index_params.add_index(\n",
    "    #     field_name=\"content_vector\",\n",
    "    #     index_type=\"IVF_FLAT\",\n",
    "    #     metric_type=\"COSINE\",\n",
    "    #     params={\"nlist\": 128}\n",
    "    # )\n",
    "    \n",
    "    # HNSW\n",
    "    index_params = client.prepare_index_params()\n",
    "    index_params.add_index(\n",
    "        field_name=\"content_vector\",\n",
    "        index_type=\"HNSW\",\n",
    "        metric_type=\"COSINE\",\n",
    "        params={\"M\": 64, \"efConstruction\": 250}\n",
    "    )\n",
    "\n",
    "    client.create_index(\n",
    "        collection_name=collection_name,\n",
    "        index_params=index_params,\n",
    "        sync=False)\n",
    "\n",
    "\n",
    "create_collection()\n",
    "client.list_indexes(collection_name=\"cumt_gpt_qwen\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 插入数据单元\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, MilvusClient\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "# from sonyflake import SonyFlake\n",
    "\n",
    "client = MilvusClient(uri=\"http://192.168.200.130:19530\")\n",
    "\n",
    "def emb_text(text):\n",
    "    # embedding_model = SentenceTransformer('maidalun1020/bce-embedding-base_v1')\n",
    "    # embedding_vectors = embedding_model.encode(text, batch_size=1024)\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    \n",
    "    embedding_model = OllamaEmbeddings(model=\"qwen2.5:7b\")\n",
    "    embedding_vectors = []\n",
    "    \n",
    "    for text_i in text:\n",
    "        embedding_vectors.append(embedding_model.embed_query(text_i))\n",
    "\n",
    "    # embedding_vectors = normalize(embedding_vectors, norm='l2')\n",
    "    return embedding_vectors\n",
    "\n",
    "# 文档列表\n",
    "# docs = [\n",
    "#     \"Artificial intelligence was founded as an academic discipline in 1956.\",\n",
    "#     \"Alan Turing was the first person to conduct substantial research in AI.\",\n",
    "#     \"Born in Maida Vale, London, Turing was raised in southern England.\",\n",
    "# ]\n",
    "# doc = \"矿小助是一款由FlyingStudio（中国矿业大学翔工作室）开发维护的校园软件。提供课表、考试、成绩、校车校历、图书馆藏、校卡余额、宿舍电量等查询功能；同时具有课表导入日历、加权成绩计算、校园网自动登录、个性化主题背景等实用功能。\"\n",
    "\n",
    "contents = []\n",
    "\n",
    "# 打开 JSON 文件\n",
    "filename = '../raw_data/articles.json'\n",
    "# filename = ('../raw_data/kxz.json')\n",
    "# filename = '../raw_data/news.json'\n",
    "# filename = '../raw_data/矿大新闻网.json'\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    python_data = json.load(f)\n",
    "    for data in python_data['data']:\n",
    "        contents.append(data.get(\"content\"))\n",
    "\n",
    "vectors = emb_text(contents)\n",
    "\n",
    "# 要插入的数据\n",
    "datas = []\n",
    "i = 0\n",
    "for data in python_data['data']:\n",
    "    # 创建一个 SonyFlake 实例\n",
    "    # flake = SonyFlake()\n",
    "\n",
    "    # 生成唯一ID\n",
    "    # sonyflake_id = flake.next_id()\n",
    "    \n",
    "    # 使用 strptime 将字符串解析为日期对象\n",
    "    date_obj = datetime.strptime(data.get(\"date\"), \"%Y-%m-%d\")\n",
    "    \n",
    "    # 使用 strftime 格式化为所需的格式，并将其转换为整数\n",
    "    date_int = int(date_obj.strftime(\"%Y%m%d\"))\n",
    "\n",
    "    datas.append({\n",
    "            # \"id\": sonyflake_id,\n",
    "            \"url\": data.get(\"url\"),\n",
    "            \"content\": data.get(\"content\"),\n",
    "            \"content_vector\": vectors[i],\n",
    "            \"publish_time\": date_int\n",
    "        })\n",
    "    i += 1\n",
    "\n",
    "# 打印每个向量的维度和生成的嵌入\n",
    "print(\"向量数量: \", len(vectors))\n",
    "print(\"向量维度: \", len(vectors[0]))\n",
    "# print(contents)\n",
    "# print(\"生成的向量:\", vectors)\n",
    "\n",
    "# 插入数据\n",
    "res = client.insert(collection_name=\"cumt_gpt_qwen\", data=datas)\n",
    "print(res)\n"
   ],
   "id": "1b157dbc4b0e3500",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 测试向量搜索单元\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, MilvusClient\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "client = MilvusClient(uri=\"http://192.168.200.130:19530\")\n",
    "\n",
    "def emb_text(text):\n",
    "    # embedding_model = SentenceTransformer('maidalun1020/bce-embedding-base_v1')\n",
    "    # embedding_vectors = embedding_model.encode(text, batch_size=1024)\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    \n",
    "    embedding_model = OllamaEmbeddings(model=\"qwen2.5:7b\")\n",
    "    embedding_vectors = []\n",
    "    \n",
    "    for text_i in text:\n",
    "        embedding_vectors.append(embedding_model.embed_query(text_i))\n",
    "    \n",
    "    # embedding_vectors = normalize(embedding_vectors, norm='l2')\n",
    "    return embedding_vectors\n",
    "\n",
    "doc = \"孙杨什么时候来学校\"\n",
    "\n",
    "doc_vector = emb_text(doc)\n",
    "\n",
    "search_params = {\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {}\n",
    "}\n",
    "\n",
    "# IVF_FLAT\n",
    "# res = client.search(\n",
    "#     collection_name=\"cumt_gpt_qwen\",\n",
    "#     data=doc_vector,\n",
    "#     limit=10,\n",
    "#     output_fields=[\"id\", \"url\", \"content\", \"publish_time\"],\n",
    "#     search_params=search_params\n",
    "# )\n",
    "\n",
    "# HNSW\n",
    "res = client.search(\n",
    "  collection_name=\"cumt_gpt_qwen\", # Collection name\n",
    "  data=doc_vector, # Replace with your query vector\n",
    "  search_params={\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"ef\":150, \"radius\":0}, # Search parameters\n",
    "  }, # Search parameters\n",
    "  limit=10, # Max. number of search results to return\n",
    "  output_fields=[\"id\",\"url\",\"content\",\"publish_time\"], # Fields to return in the search results\n",
    "  consistency_level=\"Bounded\"\n",
    ")\n",
    "\n",
    "\n",
    "print(res)"
   ],
   "id": "92d5192b3c917466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "11f30e89c07dc0e2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
